---
title: Running design critiques to improve the service
description: We conducted three design critiques to review key user journeys and identify opportunities for improvement in the service
date: 2025-06-13
tags:
  - design critique
---

We conducted three design critiques to review key user journeys and identify opportunities for improvement in the service. These sessions provided us with valuable feedback on interaction patterns, content design, and service logic.

Each session helped us refine the design and surface opportunities for further iteration.

## Why we ran design critiques

We wanted to test whether the service was easy to use and understand.

We designed the crits to:

- explore the end-to-end journeys for managing providers
- check how well the content and components worked in context
- get a broader range of perspectives from colleagues across different disciplines

This helped us avoid design decisions being made in isolation.

## What we reviewed

Each crit followed the same format. We demoed the prototype in three main parts:

1. Adding and editing providers
2. Managing provider details - including addresses, accreditations, contacts and partnerships
3. Viewing the activity log - both globally and at the provider level

We shared our screen to walk through each flow. After each section, we asked participants to add feedback on a Lucid board.

The board was pre-populated with screenshots. Participants added comments using colour-coded sticky notes:

- üü¢ green for what works well
- üü† orange for anything unclear or confusing
- üî¥ red for blockers or pain points
- üîµ blue for ideas and opportunities

## Who took part

We held three sessions.

Crit 1 included:

- 1 interaction designer
- 1 content designer
- 1 user researcher

Crit 2 included:

- 1 interaction designer
- 1 content designer
- 2 user researchers

Crit 3 included:

- 3 product managers
- 2 delivery managers

We will invite more disciplines next time, such as developers, policy colleagues and others from the wider DfE community.

## What we learned

### What works well

Flows are logical and intuitive, especially for adding providers and managing partnerships.

Activity visibility - participants liked being able to see a history of changes.

Lookup fields - tools like postcode lookups and autocomplete reduce effort.

### What is unclear or confusing

Terminology - acronyms like UKPRN and URN were not always clear; field hints lacked context.

Field behaviour - for example, should an empty end date mean a record is ongoing?

Buttons and links - having too many ‚ÄúChange‚Äù links in a row can confuse users.

Visual consistency - inconsistent headings and link labels made some pages feel unpolished.

### Blockers and pain points

Address limitations - participants questions why they could not add multiple addresses during the ‚ÄòAdd provider‚Äô flow.

Destructive actions - archive and delete buttons felt too easy to select by mistake.

Accreditation logic - participants were unsure about date rules, expiry handling and error messages.

### Ideas and opportunities

Content support - add help links and hint text, especially for codes like UKPRN and provider type.

Interaction design - reduce the number of change links by using the summary card pattern.

System feedback - make it transparent why we show data like geolocation and how it is generated.

Future expansion - participants wanted to see functionality for early years initial teacher training, early career framework (ECF), national professional qualifications (NPQ) and other types of providers.

### Recommendations

Use GOV.UK patterns more consistently for labels, headings and actions.

Improve the flow for destructive actions including the content in the confirmation steps.

Make validation and business rules more visible in the user interface.

Review and simplify the edit experience.

Add more contextual content in areas where institutional knowledge is assumed.

## What we will do next

We will:

- make changes to the prototype based on the feedback
- continue testing and refining with users
- plan future crits that include a broader range of perspectives
