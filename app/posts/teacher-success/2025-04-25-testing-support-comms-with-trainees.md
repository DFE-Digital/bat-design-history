---
title: Testing supportive comms with trainee teachers
description: Detailing email comms we sent to trainees to test their engagement with supportive content from Department for Education
date: 2025-04-25
tags:
  - withdrawals
  - trainees
  - emails
  - comms
---

We wanted to test engagement from trainees with supportive email comms from Department for Education.

![View full comms test results](Comms-testing-results.pdf).

## Method

Using the 2024/25 trainee data from Register trainee teachers, we used the Mailchimp platform to email all current trainees.

## Testing limitations

At this point in the cycle (March/April), most training is already well under way. This
will likely have an impact on engagement if the need for this information is up front,
in which case, we've missed the boat.​

We're mainly signposting to existing content provided externally – we will not be able
to measure how useful the content is or what issues they're having that led them to
click on support links.

## What we tested

We used a multivariate test with 4 variations:

- non-teaching branded, lesson planning then get support
- non-teaching branded, get support then lesson planning​
- teaching branded, lesson planning then get support​
- teaching branded, get support then lesson planning

We wanted to make sure that the ordering of the content did not have an impact on what users clicked on so we sent different versions of the email where we changed the order.

We also wanted to test engagement with a teaching branded email vs a more GDS style email.

![screenshot of GOV.UK style email](GDS-style-email.png)

![screenshot of teaching branded email](teaching-branded-email.png)

## Overall testing performance

Engagement was good with an average open rate of 54.3% and average click through rate of 5.6%.

## General findings

### September vs January starts

While open rate was actually lower for January starts, click through rate and
engagement with content was higher.​

This supports our hypothesis that trainees earlier on in their placements will benefit
more from access to teaching resources and support.

### Teaching branding

Using the teaching branding didn’t have a significant impact on engagement compared to using the GOV.UK styling.​

The GOV.UK style email had a slightly higher open rate, but given we only changed the content of the email itself and nothing about the subject line or sender, there was no discernible reason for a difference between open rates.​

The teaching brand style email had a slightly higher click through rate.

### Lesson planning vs get support

Engagement with lesson planning resources was higher than engagement with the Education Support link.

### SCITT vs HEI

Open rate was slightly higher for HEI trainees in the September cohort but lower in the January cohort.

More SCITT trainees clicked on both lesson planning and support links in the September cohort.

More SCITT trainees clicked on lesson planning links in the January cohort byt more HEI trainees clicked on support links.

### Engagement by phase

Open rate for primary trainees was higher in the September cohort but lower in the January cohort.

Lesson planning clicks was lower for primary trainees in both September and January cohorts.

Education Support clicks was lower for primary trainees in both September and January cohort.

### Engagement by subject

Subjects with a larger cohort generally had higher engagement with our comms.

However, engagement by subject can be hard to compare given some subject have bery few trainees compared to more popular courses.

## Next steps

We'll test further comms with next year's cohort (2025/26) which should see higher engagement as the comms will be more relevant.

