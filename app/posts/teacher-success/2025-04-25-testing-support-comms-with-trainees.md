---
title: Testing supportive communications with trainee teachers
description: Detailing email communications we sent to trainees to test their engagement with supportive content from Department for Education
date: 2025-04-25
tags:
  - withdrawals
  - trainees
  - emails
  - communications
---

We wanted to test engagement from trainees with supportive email communications from Department for Education.

[Download the full test results as a PDF (398KB)](comms-testing-results.pdf).

## Method

Using the 2024 to 2025 trainee data from Register trainee teachers, we used the Mailchimp platform to email all current trainees.

## Testing limitations

At this point in the cycle (March/April), most training is already well under way. This will likely have an impact on engagement if the need for this information is up front, in which case, we’ve missed the opportunity.​

We’re mainly signposting to existing content provided externally – we will not be able to measure how useful the content is or what issues they’re having that led them to click on support links.

## What we tested

We used a multivariate test with 4 variations:

- non-teaching branded, lesson planning then get support
- non-teaching branded, get support then lesson planning​
- teaching branded, lesson planning then get support​
- teaching branded, get support then lesson planning

We wanted to make sure that the ordering of the content did not have an impact on what users clicked on so we sent different versions of the email where we changed the order.

We also wanted to test engagement with a Get Into Teaching-branded email versus a more GOV.UK style email.

![screenshot of GOV.UK style email](govuk-style-email.png "Screenshot of the GOV.UK style email")

![screenshot of Get Into Teaching branded email](teaching-branded-email.png "Screenshot of the Get Into Teaching branded email")

## Overall testing performance

Engagement was good with an average open rate of 54.3% and average click through rate of 5.6%.

## General findings

### September vs January starts

While open rate was actually lower for January starts, click through rate and
engagement with content was higher.​

This supports our hypothesis that trainees earlier on in their placements will benefit more from access to teaching resources and support.

### Teaching branding

Using the teaching branding did not have a significant impact on engagement compared to using the GOV.UK styling.​

The GOV.UK style email had a slightly higher open rate, but given we only changed the content of the email itself and nothing about the subject line or sender, there was no discernible reason for a difference between open rates.​

The teaching brand style email had a slightly higher click through rate.

### Lesson planning versus get support

Engagement with lesson planning resources was higher than engagement with the Education Support link.

### SCITT versus HEI

Open rate was slightly higher for HEI trainees in the September cohort but lower in the January cohort.

More SCITT trainees clicked on both lesson planning and support links in the September cohort.

More SCITT trainees clicked on lesson planning links in the January cohort but more HEI trainees clicked on support links.

### Engagement by phase

Open rate for primary trainees was higher in the September cohort but lower in the January cohort.

Lesson planning clicks was lower for primary trainees in both September and January cohorts.

Education Support clicks was lower for primary trainees in both September and January cohorts.

### Engagement by subject

Subjects with a larger cohort generally had higher engagement with our communications.

However, engagement by subject can be hard to compare given some subject have very few trainees compared to more popular courses.

## Next steps

We’ll test further communications with next year’s cohort (2025 to 2026) which should see higher engagement as the communications will be more relevant.

*[HEI]: higher education institution
*[SCITT]: school-centred initial teacher training
